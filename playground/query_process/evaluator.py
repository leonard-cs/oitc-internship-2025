from langchain_core.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)
from langchain_core.runnables import RunnablePassthrough
from langchain_ollama import ChatOllama
from pydantic import BaseModel, Field

import os
from pathlib import Path
from dotenv import load_dotenv

load_dotenv(dotenv_path=Path("./playground/.env"))
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", default="http://localhost:11500")
PHI3 = os.getenv("PHI3", default="phi3")


class Result(BaseModel):
    generated_summary: str = Field(description="The summary generated by the model.")
    judgment: bool = Field(
        description="Evaluation judgment: 'true' if the summary is accurate, 'false' if it is misleading or wrong."
    )
    explanation: str = Field(
        description="Explanation of the evaluation judgment, why the summary is considered accurate or misleading."
    )


def evaluate_summary_with_llm(
    reference_summary: str,
    generated_summary: str,
) -> Result:
    """
    Uses an LLM to evaluate whether the generated summary is accurate and complete
    compared to the original query and the reference summary.

    Returns: Evaluation judgment as a string ("Correct", "Partially correct", "Incorrect")
    """
    # system_prompt = SystemMessagePromptTemplate.from_template(
    #     "You are an expert evaluator that compares a generated summary to a reference summary. "
    #     "Your task is to determine whether the generated summary semantically matches the reference.\n\n"
    #     "Return strictly one of the following:\n"
    #     "- true: if the summary is accurate and complete (semantically equivalent).\n"
    #     "- false: if the summary is incorrect, incomplete, or changes the meaning.\n\n"
    #     "Do not explain your answer. Only return true or false."
    # )
    system_prompt = SystemMessagePromptTemplate.from_template("""
You are an evaluator for a query-processing system that prepares user queries for a database retrieval chatbot.

You will compare two strings:
1. `generated_summary`: the cleaned version of the user input generated by the system.
2. `reference_summary`: the ideal reference version of the cleaned query.

Determine if the `generated_summary` conveys the **same retrieval intent** as the `reference_summary`, even if phrased differently. Allow for paraphrasing, rewording, and changes in tone, as long as:
- The **core meaning** and **semantic filters** (like fields, conditions, and timeframe) are preserved.
- The phrasing would still retrieve the **same or nearly equivalent data** from a database.

Mark the output as:
- **"true"** - if the generated query and processed query would result in the same database results.
- **"false"** - if any change introduces or removes a critical condition (e.g., incorrect time, entity, or field) that would meaningfully alter the retrieval results.

Be tolerant of changes in format (e.g., “list of…” vs. “products that are…”), article use, or tense — but be strict about differences in time ranges, filters, or entities.

Also include a short explanation for your decision.
""")

    user_prompt = HumanMessagePromptTemplate.from_template(
        """Reference Summary:\n{reference_summary}\n\n
           Generated Summary:\n{generated_summary}\n\n
           Are the meanings similar?""",
        input_variables=["reference_summary", "generated_summary"],
    )
    # print(user_prompt.format(
    #     reference_summary=reference_summary,
    #     generated_summary=generated_summary,
    # ))

    evaluation_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])
    # print(evaluation_prompt.format(
    #     reference_summary=reference_summary,
    #     generated_summary=generated_summary,
    # ))
    evaluation_llm = ChatOllama(
        model=PHI3, base_url=OLLAMA_BASE_URL, temperature=0.0
    ).with_structured_output(Result)
    chain = (
        {
            "reference_summary": RunnablePassthrough(),
            "generated_summary": RunnablePassthrough(),
        }
        | evaluation_prompt
        | evaluation_llm
    )
    response = chain.invoke(
        {
            "reference_summary": reference_summary,
            "generated_summary": generated_summary,
        }
    )

    return response


if __name__ == "__main__":
    result = evaluate_summary_with_llm(
        reference_summary="Most profitable product query",
        generated_summary="Most profitable product query",
    )
    print(result)
