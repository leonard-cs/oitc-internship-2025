# Agent

## Table of Contents
- [Knowledge](#-knowledge)
- [LangChain Custom Agent](#langchain-custom-agent)
- [LangGraph Agent](#langgraph-agent)
- [Reference](#reference)

## üß† Knowledge
### Memory
We can implement a **write module** to decide which information should be stored in a vector database as memory. Similarly, a **retrieve module** can be used to fetch relevant memory from the vector database.
- Prioritize storing **positive feedback** (e.g. successful task completions).
- Avoid storing **negative feedback** (e.g. what not to do). For instance, instead of telling the LLM ‚Äúdon‚Äôt give long responses,‚Äù prefer instructing it with ‚Äúgive short responses.‚Äù
- A possible implementation: when the LLM successfully completes a task and the user gives a üëç (thumbs up), that success can be stored in memory. Later, when a similar task arises, the agent can retrieve this successful memory to improve performance.

## LangChain Custom Agent

A handcrafted agent implementation using LangChain with a custom execution loop. This agent provides flexible tool integration and robust error handling for both vector search and SQL database operations.

**Files:**
- `backend/app/agent/custom_agent_executor.py` - Main agent executor
- `backend/app/agent/tools.py` - Tool definitions
- `backend/app/agent/models.py` - Response models
- `backend/app/agent/utils.py` - Utility functions

### Available Tools

The agent has access to five specialized tools (see `backend/app/agent/tools.py`):

1. **vector_search** üîç: Semantic search across document collections
2. **get_table_names** üìã: Discover available database tables
3. **get_table_schema** üèóÔ∏è: Retrieve detailed table structure information
4. **execute_sql_tool** ‚ö°: Execute SQL queries with error handling
5. **direct_answer** ‚úÖ: Terminate agent loop with structured response

### Tool Mapping System

```python
name2tool = {tool.name: tool.func for tool in tools}
```

The agent uses a dynamic tool mapping system that:
- Maps tool names to their actual functions
- Enables runtime tool execution: `name2tool[tool_name](**tool_args)`

### Response Model

The agent returns structured responses using the `AgentResponse` model:

```python
class AgentResponse(BaseModel):
    answer: str = Field(description="The final answer generated by the LLM.")
    sources: list[str] = Field(description="List of source document identifiers.")
    tools_used: list[str] = Field(description="List of tool names used to generate the answer.")
```

### Error Handling & Recovery

1. **Thinking Tag Removal**\
The agent sometimes generates content with `<think>...</think>` tags. The `remove_thinking_tags()` utility function cleans this

2. **Iteration Limits**
- Maximum iteration protection (`max_iterations = 10`)
- Graceful degradation when limits are reached
- Fallback to direct answers

### Current Limitations

- **No Memory**: Each query is processed independently without conversation history
- **Single Query Focus**: No multi-turn conversation support
- **Manual Loop**: Requires custom iteration management
- **Limited Streaming**: No real-time output streaming capabilities

## LangGraph Agent

A modern LangGraph implementation of the agent with built-in memory, advanced streaming capabilities, and SQL database interaction. This agent provides a more robust and flexible architecture compared to the custom LangChain agent.

**File:** `backend/app/agent/agent_langgraph.py`

### Key Features

- **Memory Support**: Built-in conversation memory using `MemorySaver`
- **Multiple Streaming Modes**: Various output streaming options for real-time interaction
- **SQL Database Integration**: Full SQL toolkit for database queries and analysis using `SQLDatabaseToolkit`


### Streaming Capabilities

The LangGraph agent offers multiple streaming modes for different use cases:

1. Message Streaming (`stream_agent_messages`)\
Streams complete agent messages and responses:

2. Token Streaming (`stream_agent_tokens`)\
Streams individual tokens for real-time text generation:

3. Progress Updates (`stream_agent_progress`)\
Streams internal agent state updates

4. Tool Updates (`stream_tool_updates`)\
Streams custom tool execution updates

5. Custom Streaming (`custom_streaming`)\
Combines multiple streaming modes for comprehensive output

### Memory Management

The agent uses `MemorySaver` for conversation persistence:

```python
memory = MemorySaver()
config = {"configurable": {"thread_id": "abc123"}}
```

Each conversation thread maintains its own memory context, allowing for:
- Multi-turn conversations
- User preference memory
- Session-based interactions

### Current Limitations

- **No Vector RAG**: Currently only supports SQL database interactions
- **Testing Phase**: Still in development and testing
- **Limited Tool Set**: Fewer custom tools compared to the LangChain agent

## Reference
- [LangChain AgentExecutor (Legacy)](https://python.langchain.com/docs/how_to/agent_executor/)
- [LangChain SQLDatabase Docs](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html)
- [LangGraph Agent Tutorial](https://python.langchain.com/docs/tutorials/agents/)
- [LangGraph SQL Agent Tutorial](https://python.langchain.com/docs/tutorials/sql_qa/#agents)
- [LangGraph Stream Output](https://langchain-ai.github.io/langgraph/how-tos/streaming/)